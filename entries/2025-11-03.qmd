---
title: "2025-11-03"
format:
  html: default
  pdf: default
params:
  course: "mc501"
  word_min: 450
  word_max: 500
  p1: 'Have you ever worked with a spreadsheet, dataset, or even a shared document that felt chaotic or disorganized? Describe the experience. What kinds of "messiness" did you encounter? Looking back, which data wrangling principles from this chapter would have helped clean it up?'

---

## Choose **one** prompt to answer

> **Prompt A:** `r params$p1`

---

## Response

<!-- RESPONSE-START -->
As mentioned in previous journal entries, I have spent a large chunk of my work life in Chicago-based tech startup offices. Examples of such offices include: coupon juggernaut of yesteryear Groupon (groupon.com), social media analytics standout Sprout Social (sproutsocial.com) and office perk management platform Crafty (craftydelivers.com). I have also been fortunate enough to work in other/physical data management in places like office managing a private PreK-8 school of over 220 families, medical billing for an insurance company and a prism’s worth of Pantone at a food packaging design firm. As I rose through the ranks of middling roles, I became more and more immersed in data. First through physical files that retained confidential health info dating back to the 1970s, to one-thousand shared Google docs and eventually realtime team-based idea mapping inside of Notion.

I have been fortunate enough to work with some incredible teammates over the years whose speciality was data hygiene. I have worked hard on my own and collaboratively to find streamlined processes and structured protocols. Other datasets withered on the vine due to neglect and spinning plates, leaving important team docs un-updated. A manager from my last office (Crafty) compared workplace experience team documentation, or lack thereof, as “tribal knowledge”.The inner workings of an office of 20 to 800 and recurring tasks required to keep things running smoothly can be slippery the ever-present flux of a tech start-up. This is all to say, I have weathered the messiness of working with multiple humans.

However, since this is a Research Methods class, I will attest that analyzing data is not my strong suit. Capital “D” data has shown up in my current work life through my graduate assistantship as I grow more adept in Qualtrics, wrestle with RStudio, collate specific scholastic data for the Provost office from SIUE’s many, many majors/ departments/ schools and continue to keep my skills sharp in Excel/Google Sheets. Through working in this class, I’m definitely recalibrating how I work with data, more specifically making sense of numerous data points.

Reading through the data wrangling principles in this week’s chapter, Importing is the most significant principle from where I currently stand. I would even take a step back from the importing process and shine a bright light on the importance of forming reproducible workflows. Ensuring that there is no duplicative work involved on your team, whether it be research or otherwise, is also crucial. At the end of the day, you and your team need to be on the same page as to who handles and updates what. As this class barrels towards the raw information-collecting stage with our surveys and then onto the meaningful insight stage, I must acknowledge my experience and preference for qualitative research.
<!-- RESPONSE-END -->

---

## Word Count & Range Check

```{r}
#| echo: false
#| message: false
#| warning: false
get_response_text <- function() {
  f <- knitr::current_input()
  if (is.null(f) || !file.exists(f)) return("")
  x <- readLines(f, warn = FALSE)
  # Find the lines that EXACTLY match the start/end markers
  s <- grep("^<!-- RESPONSE-START -->$", x)
  e <- grep("^<!-- RESPONSE-END -->$", x)
  if (length(s) != 1 || length(e) != 1 || e <= s) return("")
  paste(x[(s + 1L):(e - 1L)], collapse = "\n")
}
count_words <- function(txt) {
  # Remove code blocks and inline code before counting
  txt <- gsub("```[\\s\\S]*?```", " ", txt, perl = TRUE)
  txt <- gsub("`[^`]*`", " ", txt, perl = TRUE)
  # Keep letters, numbers, spaces, hyphens, and apostrophes
  txt <- gsub("[^\\p{L}\\p{N}\\s'-]", " ", txt, perl = TRUE)
  # Split by whitespace and count non-empty words
  words <- unlist(strsplit(txt, "\\s+", perl = TRUE))
  words <- words[nzchar(words)]
  length(words)
}
txt <- get_response_text()
n <- count_words(txt)
minw <- as.integer(params$word_min)
maxw <- as.integer(params$word_max)
in_range <- n >= minw && n <= maxw
cat(sprintf("**Word count:** %d  \n", n))
cat(sprintf("**Required range (%s):** %d–%d words  \n",
            toupper(params$course), minw, maxw))
cat(if (in_range) "**Status:** ✅ In range\n" else "**Status:** ❌ Out of range\n")
```
